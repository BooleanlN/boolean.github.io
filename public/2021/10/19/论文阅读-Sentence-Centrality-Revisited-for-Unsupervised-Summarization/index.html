<!DOCTYPE html>
<html lang="en">

<head>

  <!-- Minima -->
  <!-- Hexo theme created by @adisaktijrs -->

  <!-- Basic Page Needs
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  <meta charset="utf-8">

  
  <title>è®ºæ–‡é˜…è¯»-Sentence Centrality Revisited for Unsupervised Summarization</title>
  
  <link rel="canonical" href="http://example.com/2021/10/19/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Sentence-Centrality-Revisited-for-Unsupervised-Summarization/">
  
  <meta name="description" content="Sentence Centrality Revisited for Unsupervised Summarizationï¼ˆåŸºäºå†è®¿é—®å¥å­ä¸­å¿ƒæ€§çš„æ— ç›‘ç£æ–‡æœ¬æ‘˜è¦ç”Ÿæˆï¼‰2019.6.8 Hao Zheng. Mirella Lapata. ACL 2019 @misc&amp;#123;zheng2019sen">
  
  
  <meta name="author" content="John Doe">
  
  <meta property="og:image" content="http://example.comundefined">
  
  <meta property="og:site_name" content="Hexo" />
  <meta property="og:type" content="article" />
  <meta property="og:title" content="è®ºæ–‡é˜…è¯»-Sentence Centrality Revisited for Unsupervised Summarization" />
  
  <meta property="og:description" content="Sentence Centrality Revisited for Unsupervised Summarizationï¼ˆåŸºäºå†è®¿é—®å¥å­ä¸­å¿ƒæ€§çš„æ— ç›‘ç£æ–‡æœ¬æ‘˜è¦ç”Ÿæˆï¼‰2019.6.8 Hao Zheng. Mirella Lapata. ACL 2019 @misc&amp;#123;zheng2019sen">
  
  <meta property="og:url" content="http://example.com/2021/10/19/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Sentence-Centrality-Revisited-for-Unsupervised-Summarization/" />

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="è®ºæ–‡é˜…è¯»-Sentence Centrality Revisited for Unsupervised Summarization">
  
  <meta name="twitter:description" content="Sentence Centrality Revisited for Unsupervised Summarizationï¼ˆåŸºäºå†è®¿é—®å¥å­ä¸­å¿ƒæ€§çš„æ— ç›‘ç£æ–‡æœ¬æ‘˜è¦ç”Ÿæˆï¼‰2019.6.8 Hao Zheng. Mirella Lapata. ACL 2019 @misc&amp;#123;zheng2019sen">
  
  
  <meta name="twitter:image" content="http://example.comundefined">
  
  <meta name="twitter:url" content="http://example.com/2021/10/19/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Sentence-Centrality-Revisited-for-Unsupervised-Summarization/" />

  <!-- Mobile Specific Metas
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Preload fonts
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  <link rel="preload" href="../fonts/dm-serif-display-v4-latin-regular.woff2" as="font" type="font/woff2" crossorigin>
  <link rel="preload" href="../fonts/inter-v2-latin-regular.woff2" as="font" type="font/woff2" crossorigin>

  <!-- CSS
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  
<link rel="stylesheet" href="/css/normalize.css">

  
<link rel="stylesheet" href="/css/skeleton.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
<link rel="stylesheet" href="/css/prism-dark.css">

  
<link rel="stylesheet" href="/css/prism-line-numbers.css">

  <!-- User css -->
  
  
<link rel="stylesheet" href="/css/user.css">

  

  <!-- Favicon
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  <link rel="icon" type="image/png" href="/images/favicon.png">

  <!-- Custom Theme Color Style
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  <style>
  a:not(.icon) {
    text-decoration-color: #0FA0CE;
    background-image: linear-gradient(
      to bottom,
      rgba(0, 0, 0, 0) 50%,
      #0FA0CE 50%
    );
  }
  blockquote {
    border-left: 8px solid #0FA0CE;
  }
  .nanobar .bar {
    background: #0FA0CE;
  }
  .button.button-primary:hover,
  button.button-primary:hover,
  input[type="submit"].button-primary:hover,
  input[type="reset"].button-primary:hover,
  input[type="button"].button-primary:hover,
  .button.button-primary:focus,
  button.button-primary:focus,
  input[type="submit"].button-primary:focus,
  input[type="reset"].button-primary:focus,
  input[type="button"].button-primary:focus {
    background-color: #0FA0CE;
    border-color: #0FA0CE;
  }
  input[type="email"]:focus,
  input[type="number"]:focus,
  input[type="search"]:focus,
  input[type="text"]:focus,
  input[type="tel"]:focus,
  input[type="url"]:focus,
  input[type="password"]:focus,
  textarea:focus,
  select:focus {
    border: 1px solid #0FA0CE;
  }
</style>

  <!-- Google Analytics (With Privacy Settings On)
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  

<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div class="container">
    <div class="row">
      <div>

        <div class="row">
  <div class="two columns" style="max-width: 50px">
    <h1 class="mt-2 mode">
      <div onclick=setDarkMode(true) id="darkBtn">ğŸŒ‘</div>
      <div onclick=setDarkMode(false) id="lightBtn" class=hidden>â˜€ï¸</div>
      <script >
        if (localStorage.getItem('preferredTheme') == 'dark') {
          setDarkMode(true)
        }
        function setDarkMode(isDark) {
          var darkBtn = document.getElementById('darkBtn')
          var lightBtn = document.getElementById('lightBtn')
          if (isDark) {
            lightBtn.style.display = "block"
            darkBtn.style.display = "none"
            localStorage.setItem('preferredTheme', 'dark');
          } else {
            lightBtn.style.display = "none"
            darkBtn.style.display = "block"
            localStorage.removeItem('preferredTheme');
          }
          document.body.classList.toggle("darkmode");
        }
      </script>
    </h1>
  </div>

  <div class="six columns ml-1">
    <h1 class="mt-2">
      Hi Folks.
    </h1>
  </div>

  <div class="twelve columns">
    <div class="row">
      <div class="nine columns left">
        <a href="/">Home</a>
        
          
          <a href="/Works" class="ml">Works</a>
          
        
          
          <a href="/About" class="ml">About</a>
          
        
        
          
            <a href="mailto:1363371357@qq.com" target="_blank" class="ml">Email</a>
          
        
      </div>
    </div>
    <hr style="margin-bottom: 2.6rem">
  </div>
</div>

        <div class="trans">
            <h2>è®ºæ–‡é˜…è¯»-Sentence Centrality Revisited for Unsupervised Summarization</h2>

  <h2 id="Sentence-Centrality-Revisited-for-Unsupervised-Summarizationï¼ˆåŸºäºå†è®¿é—®å¥å­ä¸­å¿ƒæ€§çš„æ— ç›‘ç£æ–‡æœ¬æ‘˜è¦ç”Ÿæˆï¼‰"><a href="#Sentence-Centrality-Revisited-for-Unsupervised-Summarizationï¼ˆåŸºäºå†è®¿é—®å¥å­ä¸­å¿ƒæ€§çš„æ— ç›‘ç£æ–‡æœ¬æ‘˜è¦ç”Ÿæˆï¼‰" class="headerlink" title="Sentence Centrality Revisited for Unsupervised Summarizationï¼ˆåŸºäºå†è®¿é—®å¥å­ä¸­å¿ƒæ€§çš„æ— ç›‘ç£æ–‡æœ¬æ‘˜è¦ç”Ÿæˆï¼‰"></a>Sentence Centrality Revisited for Unsupervised Summarizationï¼ˆåŸºäºå†è®¿é—®å¥å­ä¸­å¿ƒæ€§çš„æ— ç›‘ç£æ–‡æœ¬æ‘˜è¦ç”Ÿæˆï¼‰</h2><p><em>2019.6.8 Hao Zheng. Mirella Lapata. ACL 2019</em></p>
<pre class="line-numbers language-none"><code class="language-none">@misc&#123;zheng2019sentence,
      title&#x3D;&#123;Sentence Centrality Revisited for Unsupervised Summarization&#125;, 
      author&#x3D;&#123;Hao Zheng and Mirella Lapata&#125;,
      year&#x3D;&#123;2019&#125;,
      eprint&#x3D;&#123;1906.03508&#125;,
      archivePrefix&#x3D;&#123;arXiv&#125;,
      primaryClass&#x3D;&#123;cs.CL&#125;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>[codeåœ°å€](<a target="_blank" rel="noopener" href="https://github.com/">https://github.com/</a> mswellhao/PacSum)</p>
<h3 id="0-Summary"><a href="#0-Summary" class="headerlink" title="0. Summary"></a>0. Summary</h3><p>ä½œè€…åœ¨æœ¬æ–‡æå‡ºäº†ä¸€ç§æ— ç›‘ç£æ–‡æœ¬æŠ½å–æ‘˜è¦æ¨¡å‹ï¼Œç›¸æ¯”äºTextRankæ–¹æ³•ï¼ŒPacSumä¸»è¦åšäº†ä¸¤æ–¹é¢æ”¹è¿›ï¼š</p>
<p>ä¸€æ˜¯ä½œè€…é‡æ–°å®šä¹‰äº†å¥å­ä¸­å¿ƒæ€§çš„è®¡ç®—æ–¹å¼ï¼Œå°†å¥å­ä¹‹é—´çš„ç›¸å¯¹ä½ç½®çº³å…¥äº†è®¡ç®—ï¼Œæ”¹è¿›äº†åº¦ä¸­å¿ƒæ€§çš„è®¡ç®—æ–¹æ³•ã€‚</p>
<p>äºŒæ˜¯é€šè¿‡BERTæ¨¡å‹è¿›è¡Œå¥å­è¯­ä¹‰çš„æ•è·ï¼Œè¿™ä¸æ–‡ç« æå‡ºæ—¶TextRankå¸¸é‡‡ç”¨çš„tf-idfåœ¨è¯­ä¹‰è¡¨ç¤ºä¸Šæœ‰äº†æå‡ï¼ˆTextRank+BERTä½œè€…è¿›è¡Œå®éªŒå‘ç°ï¼Œæ•ˆæœæ¯”tf-idfè¦å·®ï¼Œä½œè€…æ¨æµ‹æ˜¯å› ä¸ºTextRankæ¨¡å‹é”™è¯¯çš„å¥å­ä¸­å¿ƒæ€§å¯¼è‡´çš„ï¼‰</p>
<p>é™¤æ­¤ä¹‹å¤–ï¼Œä½œè€…åŸºäºå¥å­åˆ†å¸ƒå‡è®¾ï¼Œæå‡ºäº†ä¸skip-thought vectorä¸åŒçš„fine-tuneæ–¹æ³•ï¼Œå¹¶å–å¾—äº†æ›´å¥½çš„æ•ˆæœã€‚</p>
<p>ä½œè€…åœ¨è‹±æ–‡æ•°æ®é›†ã€ä¸­æ–‡æ•°æ®é›†è¿›è¡Œäº†æœ‰æ— ç›‘ç£æ¨¡å‹ã€æœ‰ç›‘ç£æ¨¡å‹çš„å®éªŒï¼Œå…¶ä¸­ï¼Œå–å¾—äº†æ¯”æ–‡ç« æå‡ºæ—¶æ— ç›‘ç£æ¨¡å‹æ›´å¥½çš„æ•ˆæœï¼Œå¹¶åœ¨è‹±æ–‡æ•°æ®é›†ä¸­ï¼Œå–å¾—äº†ä¸æœ‰ç›‘ç£æ¨¡å‹ååˆ†ç›¸è¿‘çš„åˆ†æ•°ã€‚</p>
<h3 id="1-Research-Objective-s"><a href="#1-Research-Objective-s" class="headerlink" title="1. Research Objective(s)"></a>1. <strong>Research Objective(s)</strong></h3><p>ä¸ºäº†è§£å†³æ–‡æœ¬æ‘˜è¦é¢†åŸŸï¼Œéš¾ä»¥ä¸ºä¸åŒç±»å‹çš„æ‘˜è¦ã€é¢†åŸŸã€è¯­è¨€å»è·å¾—æˆ–åˆ›å»ºå¤§è§„æ¨¡çš„é«˜è´¨é‡è®­ç»ƒæ•°æ®çš„é—®é¢˜ï¼Œä½œè€…æå‡ºä¸€ä¸ªæ™®éé€‚ç”¨çš„å›¾æ’åºç®—æ³•ï¼Œå¹¶ä¸”ä»ä¸¤ä¸ªæ–¹é¢æ”¹è¿›äº†å¥å­èŠ‚ç‚¹ä¸­å¿ƒæ€§è®¡ç®—ï¼š1)   åŸºäºBERTæ¨¡å‹ï¼Œæ•æ‰å¥å­è¯­ä¹‰ 2) ä½¿ç”¨æœ‰å‘è¾¹æ„å»ºå¥å­èŠ‚ç‚¹å›¾ï¼Œä½¿ç”¨æœ‰å‘è¾¹ï¼Œå»è¡¨æ˜ä»»æ„ä¸¤ä¸ªå¥å­çš„ä¸­å¿ƒæ€§åˆ†åˆ«è¢«ä»–ä»¬ç›¸å¯¹ä½ç½®æ‰€é€ æˆçš„å½±å“ã€‚</p>
<p>it is unrealistic to expect large-scale and high-quality training data to be available or created for different types of summaries, domains, or languages. Author revisit a popular graph-based ranking algorithm and modify how node (aka sentence) centrality is com- puted in two ways: (a) we employ BERT, a state-of-the-art neural representation learning model to better capture sentential meaning and (b) we build graphs with directed edges arguing that the contribution of any two nodes to their respective centrality is influenced by their relative position in a document.</p>
<h3 id="2-Background-Problem-Statement"><a href="#2-Background-Problem-Statement" class="headerlink" title="2. Background / Problem Statement"></a><strong>2. Background / Problem Statement</strong></h3><p><strong>èƒŒæ™¯ï¼š</strong></p>
<ul>
<li>åŸºäºç¥ç»ç½‘ç»œçš„æ–¹æ³•åœ¨æˆç™¾ä¸Šåƒçš„å¤§è§„æ¨¡æ•°æ®é›†ä¸Šå–å¾—äº†å¯è§‚çš„æ•ˆæœ</li>
</ul>
<p>Modern neural network-based approaches have achieved promising results thanks to the availability of large scale datasets containing hundreds of thousands of document-summary pairs</p>
<ul>
<li>å¤§è§„æ¨¡çš„ã€é«˜è´¨é‡çš„æ•°æ®é›†éš¾ä»¥åˆ›å»ºæˆ–è·å¾—</li>
</ul>
<p>it is unrealistic to expect that large-scale and high-quality training data will be available or created for different summarization styles</p>
<ul>
<li>æ— ç›‘ç£æ–¹æ³•æ˜¯ä¹‹å‰ç ”ç©¶çš„é‡ç‚¹ï¼Œå…¶ä¸­æ¯”è¾ƒæµè¡Œçš„æ˜¯åŸºäºTextRankæ–¹æ³•ã€‚</li>
</ul>
<p>A very popular algorithm for extractive single-document summarization is TextRank (Mihalcea and Tarau, 2004)</p>
<p><strong>é—®é¢˜é˜è¿°ï¼š</strong></p>
<ul>
<li>æ–‡æœ¬æ‘˜è¦é¢†åŸŸï¼Œéš¾ä»¥ä¸ºä¸åŒç±»å‹çš„æ‘˜è¦ã€é¢†åŸŸã€è¯­è¨€å»è·å¾—æˆ–åˆ›å»ºå¤§è§„æ¨¡çš„é«˜è´¨é‡è®­ç»ƒæ•°æ®ã€‚</li>
</ul>
<p>it is unrealistic to expect that large-scale and high-quality training data will be available or created for different summarization styles</p>
<ul>
<li>æ— ç›‘ç£æ–¹æ³•ä¸­ï¼ŒåŸºäºå¥å­ä¸­å¿ƒæ€§çš„æ–¹å¼å¦‚TextRankå¯ä»¥ä»ä¸¤æ–¹é¢æ”¹è¿›ï¼Œä¸€æ˜¯ä½¿ç”¨BERTæ¨¡å‹è·å–æ–‡æœ¬è¯­ä¹‰ï¼ŒäºŒæ˜¯æ„å»ºæœ‰å‘å›¾æ¥è¡¨ç¤ºä¸¤ä¸ªå¥å­èŠ‚ç‚¹å¯¹ç›¸äº’ä¹‹é—´çš„è´¡çŒ®æ˜¯ä¸åŒçš„</li>
</ul>
<p>We employ BERT (Devlin et al., 2018), a neural representation learn- ing model which has obtained state-of-the-art re- sults on various natural language processing tasks including textual inference, question answering, and sentiment analysis</p>
<p>we advocate that edges should be <em>directed</em>, since the contribu- tion induced by two nodesâ€™ connection to their re- spective centrality can be in many cases unequal.</p>
<h3 id="3-Method-s"><a href="#3-Method-s" class="headerlink" title="3. Method(s)"></a>3. <strong>Method(s)</strong></h3><p><strong>3.1 å¥å­ä¸­å¿ƒæ€§è®¡ç®—</strong></p>
<p><strong>3.1.1 æ— å‘å›¾è®¡ç®—æ–¹æ³•</strong></p>
<p>A nodeâ€™s centrality can be measured by simply computing its degree or running a ranking algorithm such as PageRank</p>
<p>ç»“ç‚¹ä¸­å¿ƒæ€§è®¡ç®—å¯ä»¥ç®€å•çš„é€šè¿‡åº¦è®¡ç®—ï¼Œä¹Ÿå¯ä»¥é€šè¿‡æ’åºç®—æ³•ï¼Œå¦‚PageRankã€‚</p>
<p><strong>åº¦ä¸­å¿ƒæ€§</strong>è®¡ç®—æ–¹æ³•ï¼š<br>$$<br>centrality(si) = \sum_{j âˆˆ{1,..,iâˆ’1,i+1,..,n}}{e_{ij}}<br>$$<br><strong>TextRank</strong>è®¡ç®—æ–¹æ³•ï¼š</p>
<p>åº¦ä¸­å¿ƒæ€§è®¡ç®—æ–¹æ³•åªè€ƒè™‘å±€éƒ¨è¿é€šæ€§ï¼Œè€ŒPageRankç®—æ³•é€šè¿‡é€’å½’ä¸ºæ‰€æœ‰èŠ‚ç‚¹åˆ†é…äº†ç›¸å¯¹çš„åˆ†æ•°ï¼Œä¸é«˜å¾—åˆ†èŠ‚ç‚¹ç›¸è¿æ¥çš„èŠ‚ç‚¹å¯¹åˆ†æ•°è´¡çŒ®æ›´å¤§ã€‚</p>
<p>Whereas degree centrality only takes local connectivity into account, PageRank assigns rela- tive scores to all nodes in the graph based on the recursive principle that connections to nodes hav- ing a high score contribute more to the score of the node in question.</p>
<p><strong>3.1.2 æœ‰å‘å›¾è®¡ç®—æ–¹æ³•</strong></p>
<p>ç†è®ºæ”¯æŒï¼šRSTï¼ˆRhetorical Structure Theoryï¼‰ï¼Œä¿®è¾ç»“æ„ç†è®ºï¼Œè¡¨ç¤ºï¼Œ è¯­ç¯‡å•å…ƒé‡è¦æ€§å’Œæ˜¾è‘—æ€§æ˜¯ä¸åŒçš„ã€‚æ ¹æ®å…¶æ–‡æœ¬é‡è¦æ€§ï¼Œåˆ†ä¸ºæ ¸å¿ƒå¥ä¸é™„å±å¥ã€‚</p>
<p>The idea that textual units vary in terms of their importance or salience, has found support in various theories of discourse structure including Rhetorical Structure Theory.</p>
<p>in terms of their text importance: <em>nuclei</em> denote central segments, whereas <em>satellites</em> denote peripheral ones.</p>
<p>è®¡ç®—æ–‡æœ¬æ ¸å¿ƒæ€§çš„æ–¹æ³•ï¼šé€šè¿‡æ–‡æœ¬çš„ç›¸å¯¹ä½ç½®è¿›è¡Œè¿‘ä¼¼è®¡ç®—ï¼Œå…¶ä¸­ï¼Œæ–‡æ¡£ä¸­å‡ºç°è¾ƒæ—©çš„å¥å­åº”è¯¥æ›´æ ¸å¿ƒã€‚</p>
<p>We instead approximate nuclearity by relative position in the hope that sentences occurring earlier in a document should be more central.</p>
<p><strong>æ–¹æ³•å®ç°</strong></p>
<p>ç»™å®šä»»æ„æ¥è‡ªåŒç¯‡æ–‡æ¡£çš„å¥å­$s_i$ï¼Œ$s_j$ï¼š<br>$$<br>centrality(s_i) = \lambda_1\sum_{j&lt;i}{e_{ij}}  + \lambda_2\sum_{j&gt;i}{e_{ij}}<br>$$<br>å…¶ä¸­ï¼Œ$\lambda_1$ä¸$\lambda_2$è¡¨ç¤ºå‰å‘å¥ä¸åå‘å¥çš„æœ‰å‘è¾¹æƒé‡ç³»æ•°ã€‚</p>
<p> Î»1, Î»2 are different weights for forward- and backward-looking directed edges.</p>
<p>åœ¨å®éªŒä¸­ï¼Œæˆ‘ä»¬è®¾ç½®$\lambda_1 + \lambda_2 = 1$æ§åˆ¶è¶…å‚æ•°çš„æ•°é‡</p>
<p>During tuning experiments, we set Î»1 + Î»2 = 1 to control the number of free hyper-parameters.</p>
<p>ç»è¿‡å®éªŒï¼Œæˆ‘ä»¬å‘ç°å‰å‘ç³»æ•°$\lambda_1$è¶‹å‘äºè´Ÿå€¼ï¼Œè¿™è¡¨ç¤ºä¸å‰é¢å†…å®¹çš„ç›¸ä¼¼æ€§ï¼Œå®é™…ä¸Šä¼šæŸå®³å…¶æœ¬èº«çš„ä¸­å¿ƒæ€§ã€‚</p>
<p>we find that the optimal Î»1 tends to be negative, implying that similarity with previous content actually hurts centrality</p>
<p>æœªæ¥å¯ä»¥é€šè¿‡PageRankç­‰å°†è´Ÿå€¼è¾¹çº³å…¥è®¡ç®—ã€‚</p>
<p>Although it is possible to use some extensions of PageR- ank (Kerchove and Dooren, 2008) to take negative edges into account, we leave this to future work and only consider the definition of centrality from Equation (6) in this paper.</p>
<p><strong>3.2 è¯­å¥ç›¸ä¼¼åº¦è®¡ç®—</strong></p>
<p>è®¸å¤šTextRankæ–¹æ³•åŸºäºç¬¦å·å¥è¡¨ç¤ºï¼ˆsymbolic sentence representationsï¼‰å¦‚tf-idfè¿›è¡Œæ–‡æœ¬çš„è¡¨ç¤ºã€‚</p>
<p>There are many variations of the similarity function of TextRank (Barrios et al., 2016) based on symbolic sentence representations such as tf-idf.</p>
<p>æœ¬æ–‡é‡‡ç”¨ä¸€ç§ç¥ç»ç½‘ç»œåˆ†å¸ƒå¼è¡¨ç¤ºâ€”â€”BERTæ¨¡å‹ä½œä¸ºencoderï¼Œå¹¶é€šè¿‡ä¸€ç§å¥å­çº§åˆ«åˆ†å¸ƒå‡è®¾å¯¹å…¶è¿›è¡Œfine-tuneã€‚</p>
<p>We use BERT (Devlin et al., 2018) as our sentence encoder and fine-tune it based on a type of sentence-level distributional hypothesis</p>
<p><strong>3.2.1 å¥å­çº§åˆ†å¸ƒå¼å‡è®¾</strong></p>
<p>ä¸ºäº†å¯¹BERTæ¨¡å‹è¿›è¡Œfine-tuneï¼Œä½œè€…é‡‡ç”¨äº†ä¸€ç§å¥å­çº§åˆ†å¸ƒå¼å‡è®¾æ¥å®šä¹‰ä¸€ä¸ªè®­ç»ƒç›®æ ‡ã€‚</p>
<p>To fine-tune the BERT encoder, we exploit a type of sentence-level distributional hypothesis (Harris, 1954; Polajnar et al., 2015) as a means to define a training objective. </p>
<p>ä¸é€šè¿‡é‡æ„ç¼–ç å¥å­çš„é‚»è¿‘å¥çš„Skip-thought vectorsä¸åŒçš„æ˜¯ï¼Œä½œè€…å€Ÿç”¨äº†å•è¯åˆ†å¸ƒå¼å‡è®¾çš„è´Ÿé‡‡æ ·æ–¹æ³•ã€‚</p>
<p><strong>æŸå¤±å‡½æ•°ï¼š</strong><br>$$<br>log\sigma({v^{â€˜}<em>{s</em>{i-1}}}^Tv_{s_{i}}) + log\sigma({v^{â€˜}<em>{s</em>{i+1}}}^Tv_{s_{i}}) + E_{s Ìƒp{(s)}}[log\sigma({-v^{â€˜}}^T{v_s})]<br>$$<br>å…¶ä¸­ vs å’Œ vsâ€² å¥å­såœ¨ä¸¤ä¸ªä¸åŒå‚æ•°çš„BERT ç¼–ç å™¨çš„ä¸åŒè¡¨ç¤ºï¼Œ Ïƒæ˜¯sigmoudå‡½æ•°ï¼ŒP(s)æ˜¯åœ¨å¥å­ç©ºé—´å®šä¹‰çš„å‡åŒ€åˆ†å¸ƒã€‚</p>
<p>where vs and vsâ€² are two different representa- tions of sentence s via two differently parameter- ized BERT encoders;ï¼Œ Ïƒ is the sigmoid functionï¼Œand P (s) is a uniform distribution defined over the sentence space.</p>
<p>ä¸ºäº†å®ç°ä»¥ä¸Šå‡è®¾ï¼Œä½œè€…ä¸ºæ¯ä¸ªæ­£æ ·æœ¬ï¼Œé‡‡å–äº”ä¸ªè´Ÿæ ·æœ¬ã€‚</p>
<p><strong>ç›¸ä¼¼çŸ©é˜µï¼š</strong></p>
<p>ä¸€æ—¦è·å¾—æ–‡æ¡£Dçš„å¥å­è¡¨ç¤ºï¼Œä½œè€…é‡‡ç”¨æˆå¯¹æ±‚ç‚¹ç§¯çš„æ–¹å¼æ¥å¾—åˆ°ä¸€ä¸ªæœªæ ‡å‡†åŒ–çš„ç›¸ä¼¼çŸ©é˜µï¼š<br>$$<br>E^ Ì„_{ij} =v_i^âŠ¤v_j<br>$$<br>æ ‡å‡†åŒ–ï¼š<br>$$<br>E^ Ìƒ_{ij} = E^ Ì„_{ij}âˆ’[minE^ Ì„ +Î²(maxE^ Ì„ âˆ’ minE^ Ì„)]<br>$$</p>
<p>$$<br>E_{ij}= E^ Ìƒ_{ij}, \ if \ E^ Ìƒ&gt;0 \ , \ else \ 0<br>$$</p>
<p>Equation (5) aims to remove the effect of absolute values by emphasizing the relative contribution of different similarity scores. This is particularly im- portant for the adopted sentence representations which in some cases might assign very high values to all possible sentence pairs. Hyper-parameter Î² (Î² âˆˆ [0, 1]) controls the threshold below which the similarity score is set to 0.</p>
<h3 id="4-Evaluation"><a href="#4-Evaluation" class="headerlink" title="4. Evaluation"></a>4. <strong>Evaluation</strong></h3><p>æ•°æ®é›†ï¼šNYT ä¸ CNN/Daily Maiï¼Œä¸­æ–‡æ•°æ®é›†TTNews</p>
<p>è¶…å‚æ•°ï¼š</p>
<ul>
<li>ä¼˜åŒ–å™¨ï¼šAdam</li>
<li>åˆå§‹å­¦ä¹ ç‡ï¼š4e-6</li>
</ul>
<p>è¯„ä»·æŒ‡æ ‡ï¼š</p>
<p>ROUGE-1ã€ROUGE-2ã€ROUGE-L</p>
<p>ç»“æœï¼š</p>
<p>è‹±æ–‡æ•°æ®é›†ï¼Œåˆ†åˆ«ä¸SOTAæœ‰ç›‘ç£æ–¹æ³•ã€æ— ç›‘ç£æ–¹æ³•è¿›è¡Œæ¯”è¾ƒ</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gw5i8qwpg0j31dg0oejx2.jpg" alt="image-20211106162215196"></p>
<p>è¶…å‚æ•°è°ƒä¼˜</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gw5ia3nrtmj30n60kwq4o.jpg" alt="image-20211106162335953"></p>
<p>ä¸­æ–‡æ•°æ®é›†ï¼Œä¸æœ‰ç›‘ç£ã€æ— ç›‘ç£æ–¹æ³•è¿›è¡Œå¯¹æ¯”çš„ç»“æœ</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gw5ibp0dt1j30o60iiac8.jpg" alt="image-20211106162507741"></p>
<p>äººå·¥è¯„æµ‹ï¼Œé€šè¿‡æ„é€ QAï¼Œå¯¹ç”Ÿæˆçš„æ‘˜è¦å†…å®¹è¿›è¡Œäººå·¥è¯„æµ‹çš„ç»“æœï¼š</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gw5iq6w6noj30mq08k3zb.jpg" alt="image-20211106163903788"></p>
<h3 id="5-Conclusion"><a href="#5-Conclusion" class="headerlink" title="5. Conclusion"></a>5. <strong>Conclusion</strong></h3><p>ä½œè€…æå‡ºçš„æ–¹æ³•åœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸Šéƒ½å–å¾—äº†æ¯”å½“å‰æ— ç›‘ç£æ–‡æœ¬æŠ½å–æ‘˜è¦åŸºçº¿æ¨¡å‹æ›´å¥½çš„æ•ˆæœï¼Œå¹¶åœ¨è‹±æ–‡æ•°æ®é›†ä¸Šå–å¾—äº†ä¸æœ‰ç›‘ç£æ¨¡å‹ï¼Œå¦‚Pointer-generatorç›¸è¿‘çš„åˆ†æ•°ã€‚</p>
<p>Experimental results on three news summarization datasets demonstrated the superiority of our approach against strong baselines.</p>
<p>æœªæ¥ï¼Œä½œè€…å¸Œæœ›å°†æœ¬æ–‡æå‡ºçš„æƒ³æ³•è¿ç”¨äºæœ‰ç›‘ç£æ¨¡å‹æˆ–è€…å¤šæ–‡æ¡£æ‘˜è¦å½“ä¸­ã€‚</p>
<p>In the future, we would like to investigate whether some of the ideas introduced in this paper can improve the perfor- mance of supervised systems as well as sentence selection in multi-document summarization. </p>
<h3 id="6-Notes"><a href="#6-Notes" class="headerlink" title="6. Notes"></a>6. <strong>Notes</strong></h3><h3 id="7-References"><a href="#7-References" class="headerlink" title="7. References"></a>7. <strong>References</strong></h3>
  <p><a class="classtest-link" href="/tags/%E8%AE%BA%E6%96%87/" rel="tag">è®ºæ–‡</a> â€” Oct 19, 2021</p>
  


          <div class="row mt-2">
  
    <div class="eight columns">
      <p id="madewith">Made with â¤ and
        <a class="footer-link icon" href="https://hexo.io" target="_blank" style="text-decoration: none;" rel="noreferrer" aria-label="Hexo.io">
        <svg class="hexo svg-hov" width="14" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><title>Hexo.js</title><path d="M12 .007L1.57 6.056V18.05L12 23.995l10.43-6.049V5.952L12 .007zm4.798 17.105l-.939.521-.939-.521V12.94H9.08v4.172l-.94.521-.938-.521V6.89l.939-.521.939.521v4.172h5.84V6.89l.94-.521.938.521v10.222z"/></svg>
        </a>
        
        at <a href="https://en.wikipedia.org/wiki/Earth" target="_blank" rel="noreferrer">Earth</a>.</p>
        
    </div>

    <!-- Sepcial thanks to https://simpleicons.org/ for the icons -->
    <div class="four columns mb-3 posisi" >
      
      <a class="ml-0 footer-link icon" href="https://github.com/BooleanlN" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="GitHub">
        <svg class="github svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
      </a>
      

      

      

      

    </div>
  
</div>

        </div>
      </div>

    </div>

  </div>
  <script src="/js/nanobar.min.js"></script>
  <script>
    var options = {
      classname: 'nanobar',
      id: 'myNanobar'
    };
    var nanobar = new Nanobar(options);
    nanobar.go(30);
    nanobar.go(76);
    nanobar.go(100);
  </script>

</body>

</html>
