<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/myblog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/myblog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/myblog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/myblog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/myblog/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"booleanln.github.io","root":"/myblog/","images":"/myblog/images","scheme":"Muse","darkmode":false,"version":"8.11.1","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/myblog/js/config.js"></script>

    <meta name="description" content="Multi-document Summarization via Deep Learning Techniques: A SurveyåŸºäºæ·±åº¦å­¦ä¹ çš„å¤šæ–‡æ¡£æ‘˜è¦æ¨¡å‹ç»¼è¿° @misc&amp;#123;ma2020multidocument,       title&#x3D;&amp;#123;Multi-document Summarization via Deep Learning Techniques: A">
<meta property="og:type" content="article">
<meta property="og:title" content="è®ºæ–‡é˜…è¯»-Multi-document Summarization via Deep Learning Techniques: A Survey">
<meta property="og:url" content="http://booleanln.github.io/myblog/2021/11/08/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Multi-document-Summarization-via-Deep-Learning-Techniques-A-Survey/index.html">
<meta property="og:site_name" content="Boolean">
<meta property="og:description" content="Multi-document Summarization via Deep Learning Techniques: A SurveyåŸºäºæ·±åº¦å­¦ä¹ çš„å¤šæ–‡æ¡£æ‘˜è¦æ¨¡å‹ç»¼è¿° @misc&amp;#123;ma2020multidocument,       title&#x3D;&amp;#123;Multi-document Summarization via Deep Learning Techniques: A">
<meta property="og:locale">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNgy1gw7z2428ezj312u0aojsn.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNgy1gw7wtp5l44j310w0u00x5.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNgy1gw7yphbejuj313w0fe0wb.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNgy1gw7z7p99rdj310p0u0aes.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNgy1gw95ox3f02j31440f4q4w.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNgy1gwaau91zzlj30pk0qkjv6.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNgy1gwackd5wj8j312g0ckabf.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNgy1gwacpjz9ulj315s09wgn2.jpg">
<meta property="article:published_time" content="2021-11-08T09:07:02.000Z">
<meta property="article:modified_time" content="2022-05-07T08:44:00.003Z">
<meta property="article:author" content="Ning">
<meta property="article:tag" content="è®ºæ–‡">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://tva1.sinaimg.cn/large/008i3skNgy1gw7z2428ezj312u0aojsn.jpg">


<link rel="canonical" href="http://booleanln.github.io/myblog/2021/11/08/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Multi-document-Summarization-via-Deep-Learning-Techniques-A-Survey/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-Hans","comments":true,"permalink":"http://booleanln.github.io/myblog/2021/11/08/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Multi-document-Summarization-via-Deep-Learning-Techniques-A-Survey/","path":"2021/11/08/è®ºæ–‡é˜…è¯»-Multi-document-Summarization-via-Deep-Learning-Techniques-A-Survey/","title":"è®ºæ–‡é˜…è¯»-Multi-document Summarization via Deep Learning Techniques: A Survey"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>è®ºæ–‡é˜…è¯»-Multi-document Summarization via Deep Learning Techniques: A Survey | Boolean</title>
  





  <noscript>
    <link rel="stylesheet" href="/myblog/css/noscript.css">
  </noscript>
<link rel="alternate" href="/myblog/atom.xml" title="Boolean" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/myblog/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Boolean</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">My Blog</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/myblog/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/myblog/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-archives"><a href="/myblog/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Multi-document-Summarization-via-Deep-Learning-Techniques-A-Survey"><span class="nav-text">Multi-document Summarization via Deep Learning Techniques: A Survey</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Research-Objective-s"><span class="nav-text">Research Objective(s)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Background-Problem-Statement"><span class="nav-text">Background &#x2F; Problem Statement</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Method-s"><span class="nav-text">Method(s)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#input-document-types-%E8%BE%93%E5%85%A5%E6%96%87%E6%A1%A3%E7%B1%BB%E5%9E%8B"><span class="nav-text">input document types è¾“å…¥æ–‡æ¡£ç±»å‹</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Concatenation-Methods-%E8%BF%9E%E6%8E%A5%E6%96%B9%E6%B3%95"><span class="nav-text">Concatenation Methods è¿æ¥æ–¹æ³•</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Summarization-Construction-Types-%E6%91%98%E8%A6%81%E6%9E%84%E9%80%A0%E6%96%B9%E6%B3%95"><span class="nav-text">Summarization Construction Types æ‘˜è¦æ„é€ æ–¹æ³•</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#RNN-based-Models"><span class="nav-text">RNN based Models</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#CNN-based-Models"><span class="nav-text">CNN based Models</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#GNN-based-Models"><span class="nav-text">GNN based Models</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#PGNet-based-Models"><span class="nav-text">PGNet based Models</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Encoder-decoder-based-Models"><span class="nav-text">Encoder-decoder based Models</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Variational-Auto-Encoder-based-Models"><span class="nav-text">Variational Auto-Encoder based Models</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Transformer-based-Models"><span class="nav-text">Transformer based Models</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Deep-Hybrid-Models"><span class="nav-text">Deep Hybrid Models</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#References"><span class="nav-text">References</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Ning</p>
  <div class="site-description" itemprop="description">ğŸŒ²ğŸ˜ŠğŸ˜„ğŸ˜ğŸ˜­ğŸ˜¡ğŸ˜®â€ğŸ’¨ğŸ¯</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/myblog/archives/">
          <span class="site-state-item-count">24</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/booleanln" title="GitHub â†’ https:&#x2F;&#x2F;github.com&#x2F;booleanln" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://booleanln.github.io/myblog/2021/11/08/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Multi-document-Summarization-via-Deep-Learning-Techniques-A-Survey/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/myblog/images/avatar.gif">
      <meta itemprop="name" content="Ning">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Boolean">
      <meta itemprop="description" content="ğŸŒ²ğŸ˜ŠğŸ˜„ğŸ˜ğŸ˜­ğŸ˜¡ğŸ˜®â€ğŸ’¨ğŸ¯">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="è®ºæ–‡é˜…è¯»-Multi-document Summarization via Deep Learning Techniques: A Survey | Boolean">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          è®ºæ–‡é˜…è¯»-Multi-document Summarization via Deep Learning Techniques: A Survey
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-11-08 17:07:02" itemprop="dateCreated datePublished" datetime="2021-11-08T17:07:02+08:00">2021-11-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-05-07 16:44:00" itemprop="dateModified" datetime="2022-05-07T16:44:00+08:00">2022-05-07</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h2 id="Multi-document-Summarization-via-Deep-Learning-Techniques-A-Survey"><a href="#Multi-document-Summarization-via-Deep-Learning-Techniques-A-Survey" class="headerlink" title="Multi-document Summarization via Deep Learning Techniques: A Survey"></a>Multi-document Summarization via Deep Learning Techniques: A Survey</h2><p><em>åŸºäºæ·±åº¦å­¦ä¹ çš„å¤šæ–‡æ¡£æ‘˜è¦æ¨¡å‹ç»¼è¿°</em></p>
<pre class="line-numbers language-none"><code class="language-none">@misc&#123;ma2020multidocument,
      title&#x3D;&#123;Multi-document Summarization via Deep Learning Techniques: A Survey&#125;, 
      author&#x3D;&#123;Congbo Ma and Wei Emma Zhang and Mingyu Guo and Hu Wang and Quan Z. Sheng&#125;,
      year&#x3D;&#123;2020&#125;,
      eprint&#x3D;&#123;2011.04843&#125;,
      archivePrefix&#x3D;&#123;arXiv&#125;,
      primaryClass&#x3D;&#123;cs.CL&#125;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Research-Objective-s"><a href="#Research-Objective-s" class="headerlink" title="Research Objective(s)"></a><strong>Research Objective(s)</strong></h3><p>å¤šæ–‡æ¡£æ‘˜è¦ç»¼è¿°</p>
<span id="more"></span>
<h3 id="Background-Problem-Statement"><a href="#Background-Problem-Statement" class="headerlink" title="Background / Problem Statement"></a><strong>Background / Problem Statement</strong></h3><p>ç ”ç©¶çš„èƒŒæ™¯ä»¥åŠé—®é¢˜é™ˆè¿°ï¼šä½œè€…éœ€è¦è§£å†³çš„é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ</p>
<script type="math/tex; mode=display">
\frac{\sum_{i=1}^d{x_iy_i } } { {\sqrt{\sum_{i=1}^d{x_i^2} } {\sqrt{\sum_{i=1}^d{y_i^2} } } } }</script><h3 id="Method-s"><a href="#Method-s" class="headerlink" title="Method(s)"></a><strong>Method(s)</strong></h3><p>å¤šæ–‡æ¡£æ‘˜è¦çš„ç›®æ ‡æ˜¯ä»ä¸€æ‰¹æ–‡æ¡£é›†åˆDä¸­ç”Ÿæˆä¸€ä¸ªç®€æ´ä¸”ä¿¡æ¯ä¸°å¯Œçš„æ‘˜è¦Sumã€‚æ–‡æ¡£é›†åˆDæ˜¯ä¸»é¢˜ç›¸å…³çš„ä¸€ç³»åˆ—æ–‡æœ¬ã€‚</p>
<p>The aim of multi- document summarization is to generate a concise and informative summary ğ‘†ğ‘¢ğ‘š from a collection ofdocumentsğ·.ğ·denotesaclusteroftopic-relateddocuments{ğ‘‘ğ‘– |ğ‘–âˆˆ[1,ğ‘]},whereğ‘isthe number of documents. Each document ğ‘‘ğ‘– consists of ğ‘€ sentences ô°ˆğ‘ ğ‘–,ğ‘— | ğ‘— âˆˆ [1, ğ‘€]ô°‰. ğ‘ ğ‘–,ğ‘— refers to the ğ‘—-th sentence in the ğ‘–-th document. </p>
<p>ä½œè€…å¯¹å¤šæ–‡æ¡£æ‘˜è¦çš„æµç¨‹è¿›è¡Œäº†æ€»ç»“ä¸æ¢³ç†ï¼Œé€šå¸¸åŒ…æ‹¬1âƒ£ï¸é€‰æ‹©ä¸€ä¸ªåˆé€‚çš„æ–‡æ¡£è¿æ¥æ–¹æ³•2âƒ£ï¸å¯¹æ–‡æ¡£è¿›è¡Œé¢„å¤„ç†3âƒ£ï¸é€šè¿‡æ·±åº¦å­¦ä¹ æ¨¡å‹è·å–è¯­ä¹‰ä¸°å¯Œçš„è¡¨è¾¾4âƒ£ï¸èåˆå„ç§ç±»å‹çš„è¡¨è¾¾ï¼Œ5âƒ£ï¸å¥å­é€‰æ‹©æˆ–æ‘˜è¦ç”Ÿæˆ</p>
<p>The first step is to select an appropriate concatenation approach for input documents. The second step is pre-processing these documents, such as segmenting sentences, tokenizing non-alphabetic characters and removing punctuations [118]. Then, an appropriate deep learning based model is chosen to generate semantic rich representation for downstream tasks. The next step is to fuse these various types of representation for later sentence selection or summary generation. Finally, through these five steps, multiple documents are transformed into concise and informative summaries.</p>
<p><img data-src="https://tva1.sinaimg.cn/large/008i3skNgy1gw7z2428ezj312u0aojsn.jpg" alt="image-20211108193513722"></p>
<h4 id="input-document-types-è¾“å…¥æ–‡æ¡£ç±»å‹"><a href="#input-document-types-è¾“å…¥æ–‡æ¡£ç±»å‹" class="headerlink" title="input document types è¾“å…¥æ–‡æ¡£ç±»å‹"></a>input document types è¾“å…¥æ–‡æ¡£ç±»å‹</h4><ul>
<li><p>å¤šç¯‡çŸ­æ–‡æ¡£ Many short documents.</p>
<p>æ¯ç¯‡æ–‡æ¡£é•¿åº¦ç›¸å¯¹è¾ƒçŸ­ï¼Œä½†æ•°é‡å¾ˆå¤§ï¼Œå¦‚äº§å“è¯„è®ºç”Ÿæˆã€‚</p>
</li>
<li><p>å°‘é‡é•¿æ–‡æ¡£ Few long documents.</p>
<p>æ¯ç¯‡æ–‡æ¡£é•¿åº¦ç›¸å¯¹è¾ƒé•¿ï¼Œä½†æ•°é‡è¾ƒå°‘ï¼Œå¦‚æ–°é—»æ‘˜è¦ç”Ÿæˆã€‚</p>
</li>
<li><p>æ··åˆæ–‡æ¡£ç±»å‹ Hybrid documents. </p>
<p>ä¸€ç¯‡æˆ–å¤šç¯‡é•¿æ–‡æ¡£åŒæ—¶ä¼´éšç€è‹¥å¹²ç¯‡çŸ­æ–‡æ¡£ï¼Œå¦‚æ–°é—»ç¨¿+æ–°é—»çŸ­è¯„ï¼Œè®ºæ–‡+ç®€çŸ­çš„å¼•ç”¨ã€‚</p>
</li>
</ul>
<h4 id="Concatenation-Methods-è¿æ¥æ–¹æ³•"><a href="#Concatenation-Methods-è¿æ¥æ–¹æ³•" class="headerlink" title="Concatenation Methods è¿æ¥æ–¹æ³•"></a>Concatenation Methods è¿æ¥æ–¹æ³•</h4><ol>
<li><p>Flat Concatenation å¹³æ»‘è¿æ¥</p>
<p>å°†æ‰€æœ‰è¾“å…¥æ–‡æ¡£å›Šæ‹¬åœ¨ä¸€ä¸ªè¾“å…¥å½“ä¸­ï¼Œå¹¶å½“ä½œä¸€ä¸ªæ•´ä½“çš„sequenceè¿›è¡Œå¤„ç†ï¼Œç®€å•ä½†powerfulã€‚</p>
<p> All input documents are spanned and are processed as a flat sequence.</p>
</li>
<li><p>Hierarchical Concatenation åˆ†å±‚è¿æ¥</p>
<p>å€ŸåŠ©åˆ†å±‚è¿æ¥ï¼Œæœ‰åŠ©äºæ¨¡å‹è·å¾—è¯­ä¹‰ä¸°å¯Œçš„è¡¨ç¤ºï¼Œä»è€Œæé«˜æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚å½“å‰çš„åˆ†å±‚è¿æ¥æ–¹æ³•ï¼ŒåŒ…å«ä¸¤ç§æ–¹æ¡ˆï¼š</p>
<ul>
<li><p>æ–‡æ¡£çº§åˆ«ï¼šåˆ†åˆ«å¾—åˆ°æ–‡æ¡£çš„æ‘˜è¦è¡¨ç¤ºï¼Œè¿™äº›è¡¨ç¤ºåœ¨åç»­è¿‡ç¨‹ä¸­è¿›è¡Œèåˆã€‚</p>
<p>For the document-level concatenation methods, a condense model [3] is proposed to learn document-level representation separately in a cluster and these representation are fused in the subsequent processes.</p>
</li>
<li><p>å•è¯/å¥å­çº§åˆ«ï¼šåŒ…å«èšç±»ä¸å…³ç³»å›¾æ–¹æ³•</p>
<p><strong>èšç±»æ–¹æ³•ï¼š</strong>é¦–å…ˆå¯¹è¾“å…¥å¯¹æ–‡æ¡£è¿›è¡Œå¥å­çº§èšç±»ï¼Œç„¶åä»ä¸åŒçš„èšç±»ä¸­é€‰æ‹©å¥å­ï¼Œä¿è¯æœ€å¤šä»ä¸€ä¸ªèšç±»ä¸­é€‰æ‹©å‡ºä¸€ä¸ªå¥å­ï¼Œä»è€Œå‡å°‘å†—ä½™ä¿¡æ¯ï¼Œå¹¶æé«˜ä¿¡æ¯çš„è¦†ç›–ç‡ã€‚</p>
<p>First allowing the model group related sentences. Then, the model selects sentences from diverse clusters, and at most one sentence will be selected from a cluster. By doing so, it will decrease redundancy and increase the information coverage for the generated summaries.</p>
<p><strong>å…³ç³»å›¾æ–¹æ³•ï¼š</strong>æ„é€ å¥å­å…³ç³»å›¾æ¥è¡¨ç¤ºæ–‡æ¡£ä¹‹é—´çš„å±‚æ¬¡å…³ç³»ï¼Œå¸¸ç”¨çš„æ„é€ æ–¹æ³•æœ‰ä½™å¼¦ç›¸ä¼¼å›¾ã€è¿‘ä¼¼è¯­ç¯‡å›¾ä»¥åŠä¸ªæ€§åŒ–è¯­ç¯‡å›¾ã€‚è¿˜æœ‰ä¸€ç§å¼‚æ„å›¾æ¨¡å‹åˆ©ç”¨å•è¯æ„é€ å¥å­ä¸å¥å­ã€å¥å­ä¸æ–‡æ¡£ä¹‹é—´çš„å…³ç³»å›¾ã€‚</p>
<p>Cosine similarity graph, approximate discourse graph, and personalized discourse graph are the most commonly used methods recently for building sentence graph structures. The heterogeneous graph model leverages words as intermediate nodes to construct a document-document, sentence-sentence and sentence-document hierarchical structure.</p>
</li>
</ul>
</li>
</ol>
<p>   <img data-src="https://tva1.sinaimg.cn/large/008i3skNgy1gw7wtp5l44j310w0u00x5.jpg" alt="image-20211108181754273"></p>
<h4 id="Summarization-Construction-Types-æ‘˜è¦æ„é€ æ–¹æ³•"><a href="#Summarization-Construction-Types-æ‘˜è¦æ„é€ æ–¹æ³•" class="headerlink" title="Summarization Construction Types æ‘˜è¦æ„é€ æ–¹æ³•"></a>Summarization Construction Types æ‘˜è¦æ„é€ æ–¹æ³•</h4><ol>
<li>abstractive summarization ç”Ÿæˆå¼æ‘˜è¦</li>
<li>extractive summarization æŠ½å–å¼æ‘˜è¦</li>
<li>hybrid summarization æ··åˆæ–¹æ³•æ‘˜è¦</li>
</ol>
<p><img data-src="https://tva1.sinaimg.cn/large/008i3skNgy1gw7yphbejuj313w0fe0wb.jpg" alt="image-20211108192305082"></p>
<p>ä½œè€…æå‡ºäº†ä¸€ç§æ¦‚æ‹¬æ¨¡å‹ç»“æ„çš„æ–°æ–¹æ³•ï¼Œå°†æ¨¡å‹ç»“æ„åˆ†ä¸ºäº†ä»¥ä¸‹ç±»å‹ï¼š</p>
<p>å…¶ä¸­ï¼Œç»¿è‰²è™šçº¿boxå¯ä»¥ç”±å…¶å®ƒç½‘ç»œæ¨¡å‹çµæ´»ä»£æ›¿ï¼Œè“è‰²å®çº¿boxåˆ™è¡¨æ˜é€šè¿‡ç¥ç»ç½‘ç»œæˆ–å¯å‘å¼è®¾è®¡æ–¹æ³•è¿›è¡Œçš„åµŒå…¥æ“ä½œï¼Œå¯ä»¥æ˜¯å¥å­/æ–‡æ¡£ç­‰ç±»å‹çš„è¡¨è¾¾ã€‚</p>
<p> In this figure, deep neural models are boxed in green dotted line, which can be flexibly substituted by other backbone networks. The blue solid line boxes indicate the neural embeddings processed by neural networks or heuristic-designed approaches. It can be sentence/document representation or other types of representation. </p>
<ul>
<li><p>Naive Networks</p>
<p>æœ´ç´ ç½‘ç»œï¼ŒDNN modelä½œç”¨æ˜¯ä¸€ä¸ªç‰¹å¾æå–å™¨ï¼Œå¾—åˆ°çš„representationäº¤ç”±ä¸‹æ¸¸åšå¥å­é€‰æ‹©æˆ–æ‘˜è¦ç”Ÿæˆã€‚</p>
</li>
<li><p>Ensemble Networks.</p>
<p>é›†æˆç½‘ç»œï¼Œè¾“å…¥docuemntsè‡³å¤šä¸ªæ¨¡å‹ï¼Œä¹‹åå„æ¨¡å‹å¾—åˆ°çš„è¡¨è¾¾ä¼šè¿›è¡Œèåˆæ¥æé«˜æ¨¡å‹æ•´ä½“çš„è¡¨è¾¾èƒ½åŠ›ã€‚ä¸»æµèåˆæ–¹æ³•æœ‰æŠ•ç¥¨æˆ–å‡å€¼ã€‚</p>
<p>Ensemble networks feed input documents to multiple paths with different network structures or operations. Later on, these representations are fused to enhance model expression capability. The majority vote or average can be used to determine the final solution.</p>
</li>
<li><p>Auxiliary Task Networks</p>
</li>
</ul>
<ul>
<li>Reconstruction Networks</li>
</ul>
<ul>
<li>Fusion Networks. Fusion networks </li>
</ul>
<ul>
<li>Graph Neural Networks</li>
</ul>
<ul>
<li><p>Hierarchical Networks</p>
<p>æ–‡æ¡£é›†è¿æ¥åè¾“å…¥ç¬¬ä¸€å±‚DNNåï¼Œè·å¾—å…¶è¡¨å±‚ç‰¹å¾ï¼Œä¹‹åå°†è¯¥ç¬¬ä¸€å±‚è¾“å‡ºä½œä¸ºç¬¬äºŒå±‚DNNçš„è¾“å…¥ï¼Œç”Ÿæˆæ·±å±‚æ¬¡è¡¨å¾ï¼Œåˆ†å±‚æ¨¡å‹å¯ä»¥æ›´æœ‰æ•ˆåœ°æå–æŠ½è±¡å±‚æ¬¡å’Œè¯­ä¹‰ç‰¹å¾ã€‚</p>
<p>The Hierarchical networks empower the model with the ability to capture abstract-level and semantic-level features more efficiently.</p>
</li>
</ul>
<p><img data-src="https://tva1.sinaimg.cn/large/008i3skNgy1gw7z7p99rdj310p0u0aes.jpg" alt="image-20211108194035375"></p>
<h4 id="RNN-based-Models"><a href="#RNN-based-Models" class="headerlink" title="RNN based Models"></a>RNN based Models</h4><h4 id="CNN-based-Models"><a href="#CNN-based-Models" class="headerlink" title="CNN based Models"></a>CNN based Models</h4><h4 id="GNN-based-Models"><a href="#GNN-based-Models" class="headerlink" title="GNN based Models"></a>GNN based Models</h4><p>è‡ªç„¶è¯­è¨€æ•°æ®é€šå¸¸ç”±å…³ç³»å¯†åˆ‡çš„è¯æ±‡å’ŒçŸ­è¯­ç»„æˆï¼Œç›¸æ¯”äºåºåˆ—çš„è¡¨ç¤ºæ–¹æ³•ï¼Œå›¾ç»“æ„èƒ½å¤Ÿæ›´å¥½åœ°è¿›è¡Œè¡¨ç¤ºã€‚</p>
<p>Natural language data consist of vocabularies and phrases with strong relations and they can be better represented with graphs rather than in sequential orders</p>
<ol>
<li><p>åŸºäºGCNçš„æ–¹æ³•^[1]^ ï¼šæ„å»ºå¥å­å…³ç³»å›¾ï¼Œé€å…¥GCNè·å¾—å¥å­ç›¸å…³ç‰¹å¾ã€‚</p>
<p>This model first builds a sentence-based graph and then feeds the pre-processed data into a GCN [60] to capture the sentence-wise related features.</p>
<p><strong>æ„é€ å›¾çš„æ–¹æ³•ï¼š</strong>æ¯ä¸ªå¥å­è§†ä½œä¸€ä¸ªç»“ç‚¹ï¼Œå¥å­é—´çš„å…³ç³»ä¸ºè¾¹ï¼Œå…³ç³»æœ‰ä½™å¼¦ç›¸ä¼¼åº¦ã€è¿‘ä¼¼è¯­ç¯‡ã€ä¸ªæ€§åŒ–è¯­ç¯‡ç­‰ã€‚</p>
<p>Defined by the model, each sentence is regarded as a node and the relation between each pair of sentences is defined as an edge. Inside each document cluster, the sentence relation graph can be generated through cosine similarity graph [32], approximate discourse graph [23] and the proposed personalized discourse graph. </p>
<p>å¥å­å…³ç³»å›¾ä»¥åŠRNNæŠ½å–å‡ºembeddingï¼Œéƒ½é€å…¥å›¾å·ç§¯ç¥ç»ç½‘ç»œæ¥å¾—åˆ°å¥å­æœ€ç»ˆçš„è¡¨è¾¾ã€‚æœ€åå°†è¾“å‡ºé€å…¥<strong>æ–‡æ¡£GRU</strong>å®Œæˆé›†ç¾¤åµŒå…¥ï¼Œå®Œå…¨èšåˆå¥å­ä¹‹é—´çš„ç‰¹å¾ã€‚</p>
<p>Both of the sentence relation graph and sentence embeddings extracted by a sentence-level RNN are fed into graph convolution networks to produce the final sentence representation. With the help of a document-level GRU, the model generates cluster embeddings to fully aggregate features between sentences.</p>
<p><img data-src="https://tva1.sinaimg.cn/large/008i3skNgy1gw95ox3f02j31440f4q4w.jpg" alt="image-20211109201016184"></p>
</li>
<li><p>åŸºäºå¼‚æ„å›¾çš„æ–¹æ³•^[3]^ ï¼šä¸Šé¢çš„æ–¹æ³•åªåˆ©ç”¨äº†å¥å­çº§çš„å…³ç³»ï¼Œæ²¡æœ‰å……åˆ†è€ƒè™‘å•è¯ã€å¥å­ä»¥åŠæ–‡ç« ä¹‹é—´çš„å…³ç³»ã€‚</p>
<p>The existing graph neural networks based models are mainly focused on the relationship between sentences and do not fully consider the relations among words, sentences and documents</p>
<p> HeterDoc-Sum Graph^[3]^æ˜¯ä¸€ç§åŸºäºå¼‚æ„å›¾æ³¨æ„åŠ›ç½‘ç»œï¼Œå®ƒåŒ…å«äº†å•è¯èŠ‚ç‚¹ã€å¥å­èŠ‚ç‚¹ä»¥åŠæ–‡ç« èŠ‚ç‚¹ï¼Œå¥å­èŠ‚ç‚¹å’Œæ–‡ç« èŠ‚ç‚¹é€šè¿‡å…±ç°å•è¯å…³ç³»ç›¸è¿æ¥</p>
<p>Sentence nodes and document nodes are connected according to the contained word nodes. </p>
<p>TF-IDFå€¼ä½œä¸ºå•è¯-å¥å­ä»¥åŠå•è¯-æ–‡ç« çš„æƒé‡</p>
<p>ä¸‰ç§å…³ç³»å›¾é€å…¥å›¾æ³¨æ„åŠ›ç½‘ç»œ^[2]^ä¸­è¿›è¡Œæƒé‡æ›´æ–°ï¼Œæ¯æ¬¡æ›´æ–°æ—¶ï¼Œå¯¹å•è¯å¥å­å’Œå•è¯æ–‡æ¡£è¿›è¡ŒåŒå‘æ›´æ–°ï¼Œä»¥æ›´å¥½åœ°èšåˆè·¨å±‚è¯­ä¹‰çŸ¥è¯†ã€‚</p>
<p><img data-src="https://tva1.sinaimg.cn/large/008i3skNgy1gwaau91zzlj30pk0qkjv6.jpg" alt="image-20211110195359995"></p>
</li>
</ol>
<h4 id="PGNet-based-Models"><a href="#PGNet-based-Models" class="headerlink" title="PGNet based Models"></a>PGNet based Models</h4><p>Pointer-generator ç½‘ç»œè¢«æå‡ºæ¥è§£å†³æ‘˜è¦é¢†åŸŸçš„äº‹å®é”™è¯¯ä»¥åŠé«˜å†—ä½™æ€§é—®é¢˜ã€‚</p>
<p>Pointer-generator networks is proposed to overcome the problems of factual errors and high redundancy in the summarization task. </p>
<p>è¿™ç±»ç½‘ç»œæ¶æ„å—åˆ°äº†pointer networkã€copynetã€forced-attention sentence compression ä»¥åŠ coverage mechanismçš„å¯å‘ã€‚å¯¹è¿™äº›æ¦‚å¿µè¿›è¡Œä»‹ç»ï¼š</p>
<p><strong>pointer network</strong></p>
<p><strong>copynet</strong></p>
<p><strong>converage mechanism</strong></p>
<p><strong>MMRï¼ˆMaximal Marginal Relevanceï¼‰</strong></p>
<script type="math/tex; mode=display">
MMR = ArgMAX_{Di\ in \ æœªé€‰ä¸­é›†åˆ}[\lambda Sim_1(D_i,Q) - (1-\lambda)max_{Dj \ in \ å·²é€‰ä¸­é›†åˆ}Sim_2(Di,D_j))]</script><p><em>å…¶ä¸­Qä¸ºç”¨æˆ·ï¼Œå‰åŠéƒ¨åˆ†åœ¨æ‘˜è¦é¢†åŸŸæ˜¯å¯¹å¥å­çš„æ‰“åˆ†ã€‚</em></p>
<p>è¯¥æ–¹æ³•ç›®çš„åœ¨äºå‡å°‘æ’åºç»“æœçš„å†—ä½™ï¼Œä¿è¯ç»“æœçš„å¤šæ ·æ€§ï¼Œå¸¸ç”¨äºæ¨èé¢†åŸŸã€‚</p>
<p>More accurately, the MMR scores are multiplied to the original attention weights. MMR method is designed to select a set of salience sentences from source documents by considering both importance and redundancy indexes</p>
<h4 id="Encoder-decoder-based-Models"><a href="#Encoder-decoder-based-Models" class="headerlink" title="Encoder-decoder based Models"></a>Encoder-decoder based Models</h4><p><strong>Encoderï¼š</strong>å¯¹åŸæ–‡æ¡£è¿›è¡Œç¼–ç è¡¨ç¤ºï¼Œç¼–ç åŒ…å«äº†å‹ç¼©è¯­ä¹‰å’Œå¥æ³•ä¿¡æ¯</p>
<p><strong>Decoderï¼š</strong>å¯¹encoderçš„ç¼–ç ç»“æœè¿›è¡Œå¤„ç†ï¼Œç”Ÿæˆç›®æ ‡æ‘˜è¦</p>
<p>For multi-document summarization, the encoder embeds source documents into the hidden representations, i.e., word representation, sentence representation and document representation. Then, the representation containing compressed semantic and syntactic information is passed to the decoder to generate the target summaries. </p>
<p><img data-src="https://tva1.sinaimg.cn/large/008i3skNgy1gwackd5wj8j312g0ckabf.jpg" alt="image-20211110205341614"></p>
<h4 id="Variational-Auto-Encoder-based-Models"><a href="#Variational-Auto-Encoder-based-Models" class="headerlink" title="Variational Auto-Encoder based Models"></a>Variational Auto-Encoder based Models</h4><p>å˜åˆ†è‡ªç¼–ç å™¨ï¼š</p>
<p><img data-src="https://tva1.sinaimg.cn/large/008i3skNgy1gwacpjz9ulj315s09wgn2.jpg" alt="image-20211110205840492"></p>
<h4 id="Transformer-based-Models"><a href="#Transformer-based-Models" class="headerlink" title="Transformer based Models"></a>Transformer based Models</h4><h4 id="Deep-Hybrid-Models"><a href="#Deep-Hybrid-Models" class="headerlink" title="Deep Hybrid Models"></a>Deep Hybrid Models</h4><h3 id="References"><a href="#References" class="headerlink" title="References"></a><strong>References</strong></h3><p>[1] Michihiro Yasunaga, Rui Zhang, Kshitijh Meelu, Ayush Pareek, Krishnan Srinivasan, and Dragomir R. Radev. 2017. Graph-based Neural Multi-Document Summarization. In Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017).</p>
<p>[2] Petar VelicÌŒkovicÌ, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2017. Graph Attention Networks. arXiv preprint arXiv:1710.10903.</p>
<p>[3] Danqing Wang, Pengfei Liu, Yining Zheng, Xipeng Qiu, and Xuanjing Huang. 2020. Heterogeneous Graph Neural Networks for Extractive Document Summarization. arXiv preprint arXiv:2004.12393.</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/myblog/tags/%E8%AE%BA%E6%96%87/" rel="tag"># è®ºæ–‡</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/myblog/2021/10/23/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%BA%90%E7%A0%81%E6%8E%A2%E7%A9%B6/" rel="prev" title="çº¿ç¨‹æ± æºç æ¢ç©¶">
                  <i class="fa fa-chevron-left"></i> çº¿ç¨‹æ± æºç æ¢ç©¶
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/myblog/2021/11/10/C-%E5%88%9D%E5%B0%9D/" rel="next" title="C++åˆå°">
                  C++åˆå° <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ning</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/lozad@1.16.0/dist/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
<script src="/myblog/js/comments.js"></script><script src="/myblog/js/utils.js"></script><script src="/myblog/js/motion.js"></script><script src="/myblog/js/schemes/muse.js"></script><script src="/myblog/js/next-boot.js"></script>

  





  





</body>
</html>
